{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a63b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 wells (6507_2-1, 6507_2-2, 6507_2-4, 6507_3-9S):\n",
    "# - logs (Density, P-wave, Phi, Vcl, Water Saturation)\n",
    "# - synthetic-scaled\n",
    "# - attributes (4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d9fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "# define base color\n",
    "base_color = sb.color_palette()[0]\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645b922",
   "metadata": {},
   "source": [
    "## Read data\n",
    "### Read Logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f282f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file location\n",
    "logs_location='data/wells/Logs/'\n",
    "seismic_logs_location='data/wells/Synthetic_seismic/'\n",
    "att_logs_location='data/wells/Attributes_from_synthetic_traces/'\n",
    "\n",
    "d2_location='data/2D_1/'\n",
    "d2_2_location='data/2D_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72976f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs_1=pd.read_csv(logs_location+'6507_2-1_logs.csv') \n",
    "# gives error as we have extra rows with information in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "790dade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data with skipping 16 rows of information\n",
    "# specify column names\n",
    "logs_1=pd.read_csv(logs_location+'6507_2-1_logs.csv', skiprows=16, \n",
    "                   names = ['Time','Density','P_wave','Porosity','V_clay', 'Water Saturation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af558fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop loop to read files in folder \n",
    "\n",
    "logs = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(logs_location+'*.csv'):\n",
    "    # read file\n",
    "    df = pd.read_csv(file_name, skiprows=16, \n",
    "                     names = ['Time','Density', 'P_wave','Porosity','V_clay', 'Water Saturation'],\n",
    "                     low_memory=False)\n",
    "    \n",
    "    # add log ID to new column\n",
    "    df['log_ID']=file_name[16:-9]\n",
    "    \n",
    "    # add last file to df\n",
    "    logs = pd.concat([logs,df],axis=0)\n",
    "\n",
    "# reset index\n",
    "logs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bcd8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time                    0\n",
       "Density               935\n",
       "P_wave              19293\n",
       "Porosity            28608\n",
       "V_clay              16457\n",
       "Water Saturation    27953\n",
       "log_ID                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -999.2500 is equivalent to NaN value\n",
    "(logs==-999.2500).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d83447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all data contailing -999.2500\n",
    "logs.drop(logs.index[logs['Porosity'] == -999.2500], inplace = True)\n",
    "logs.drop(logs.index[logs['P_wave'] == -999.2500], inplace = True)\n",
    "logs.drop(logs.index[logs['Density'] == -999.2500], inplace = True)\n",
    "logs.drop(logs.index[logs['V_clay'] == -999.2500], inplace = True)\n",
    "\n",
    "# re-index dataframe\n",
    "logs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21afca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6507_2-1     26600\n",
       "6507_2-4     20025\n",
       "6507_2-2     16803\n",
       "6507_3-9S    11325\n",
       "6507_6-4A      563\n",
       "6507_5-5       326\n",
       "6507_3-6       116\n",
       "Name: log_ID, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs['log_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c81367a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Density</th>\n",
       "      <th>P_wave</th>\n",
       "      <th>Porosity</th>\n",
       "      <th>V_clay</th>\n",
       "      <th>Water Saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75758.000000</td>\n",
       "      <td>75758.000000</td>\n",
       "      <td>75758.000000</td>\n",
       "      <td>75758.000000</td>\n",
       "      <td>75758.000000</td>\n",
       "      <td>75758.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2231.724908</td>\n",
       "      <td>2.259806</td>\n",
       "      <td>2623.788348</td>\n",
       "      <td>0.131551</td>\n",
       "      <td>0.643055</td>\n",
       "      <td>0.992220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>792.450806</td>\n",
       "      <td>0.254068</td>\n",
       "      <td>625.932406</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>0.067032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>514.875700</td>\n",
       "      <td>1.254200</td>\n",
       "      <td>69.095500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1623.530175</td>\n",
       "      <td>2.085200</td>\n",
       "      <td>2170.043700</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2295.511500</td>\n",
       "      <td>2.258500</td>\n",
       "      <td>2485.396000</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2866.009375</td>\n",
       "      <td>2.481600</td>\n",
       "      <td>2997.033275</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3693.633300</td>\n",
       "      <td>3.069000</td>\n",
       "      <td>6082.184100</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time       Density        P_wave      Porosity        V_clay  \\\n",
       "count  75758.000000  75758.000000  75758.000000  75758.000000  75758.000000   \n",
       "mean    2231.724908      2.259806   2623.788348      0.131551      0.643055   \n",
       "std      792.450806      0.254068    625.932406      0.052663      0.139405   \n",
       "min      514.875700      1.254200     69.095500      0.000000      0.000000   \n",
       "25%     1623.530175      2.085200   2170.043700      0.088200      0.613300   \n",
       "50%     2295.511500      2.258500   2485.396000      0.121300      0.667600   \n",
       "75%     2866.009375      2.481600   2997.033275      0.162700      0.717900   \n",
       "max     3693.633300      3.069000   6082.184100      0.573800      1.000000   \n",
       "\n",
       "       Water Saturation  \n",
       "count      75758.000000  \n",
       "mean           0.992220  \n",
       "std            0.067032  \n",
       "min            0.000000  \n",
       "25%            1.000000  \n",
       "50%            1.000000  \n",
       "75%            1.000000  \n",
       "max            1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d297810",
   "metadata": {},
   "source": [
    "### Read synthetic seismic wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef73006",
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(seismic_logs_location+'*'):\n",
    "    # read file,  skip 1st row, specify column names\n",
    "    df=pd.read_table(file_name,skiprows=1, delim_whitespace=True, \n",
    "                     names=('Time', 'Seismic'))\n",
    "    # add log ID\n",
    "    df['log_ID']=file_name[29:-17]\n",
    "    \n",
    "    seismic = pd.concat([seismic,df],axis=0)\n",
    "\n",
    "# drop columns with NaN\n",
    "seismic.dropna(axis=1, inplace=True)\n",
    "\n",
    "# reset index\n",
    "seismic.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209b1d1",
   "metadata": {},
   "source": [
    "### Read attributes from synthetic traces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c155f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile(r'\\d+_\\d-\\dS*')\n",
    "p1 = re.compile(r'[A-Z][A-Za-z]+')\n",
    "\n",
    "seismic_att=pd.DataFrame()\n",
    "seismic_att=pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(att_logs_location):\n",
    "    for d in dirs:\n",
    "        # for each sub directory\n",
    "        count=0\n",
    "        for root_1, dirs_1, files_1 in os.walk(os.path.join(root, d)):\n",
    "            for file in files_1:\n",
    "                \n",
    "                # find attribute name from file_name string\n",
    "                column_name=p1.findall(file)[0]\n",
    "                \n",
    "                # read file\n",
    "                df=pd.read_table(os.path.join(root, d, file),skiprows=1, delim_whitespace=True, \n",
    "                     names=('Time', column_name))\n",
    "                \n",
    "                # add log ID column\n",
    "                df['log_ID']=p.findall(file)[0]\n",
    "                \n",
    "                if count==0:\n",
    "                    seismic_att1 = df\n",
    "                    count=count+1\n",
    "                else:                    \n",
    "                    seismic_att1 = pd.merge(seismic_att1,df,on=['Time', 'log_ID'])\n",
    "                        \n",
    "        seismic_att=pd.concat([seismic_att,seismic_att1],axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f5d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge seismic and seismic_attributes dataframes\n",
    "seismic_df=pd.merge(seismic,seismic_att,on=['Time', 'log_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7590f",
   "metadata": {},
   "source": [
    "### Read 2D data for exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c189ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = re.compile(r'[A-Z][A-Za-z]+')\n",
    "\n",
    "count=0\n",
    "for file in glob.glob(d2_location+'*'):\n",
    "    # find attribute name from file_name string\n",
    "    column_name=p1.findall(file)[0]\n",
    "                \n",
    "    # read file\n",
    "    df=pd.read_table(file,skiprows=0, delim_whitespace=True, \n",
    "                    names=('Time', column_name, 'X', 'Trace'))\n",
    "    # fill in trace nr\n",
    "    df['Trace'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    if count==0:\n",
    "        section_stack=df\n",
    "        count=count+1\n",
    "    else:\n",
    "        section_stack=pd.merge(section_stack, df, on=['Time', 'X', 'Trace']) \n",
    "        \n",
    "# remove rows that contain '-> Trace # XXX'\n",
    "section_stack.drop(section_stack[section_stack['X']=='#'].index, inplace=True)\n",
    "# remocve column 'X'\n",
    "section_stack.drop('X', axis=1, inplace=True)\n",
    "# reset index\n",
    "section_stack.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034bf549",
   "metadata": {},
   "source": [
    "### Read 2D data for exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f4a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for file in glob.glob(d2_2_location+'*'):\n",
    "    # find attribute name from file_name string\n",
    "    column_name=file[10:-8]\n",
    "                \n",
    "    # read file\n",
    "    df=pd.read_table(file,skiprows=0, delim_whitespace=True, \n",
    "                    names=('Time', column_name, 'X', 'Trace'))\n",
    "    # fill in trace nr\n",
    "    df['Trace'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    if count==0:\n",
    "        section_stack2=df\n",
    "        count=count+1\n",
    "    else:\n",
    "        section_stack2=pd.merge(section_stack2, df, on=['Time', 'X', 'Trace'], how='outer') \n",
    "        \n",
    "# remove rows that contain '-> Trace # XXX'\n",
    "section_stack2.drop(section_stack2[section_stack2['X']=='#'].index, inplace=True)\n",
    "# remove column 'X'\n",
    "section_stack2.drop('X', axis=1, inplace=True)\n",
    "# reset index\n",
    "section_stack2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648f2fa",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e630da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs:  Index(['Time', 'Density', 'P_wave', 'Porosity', 'V_clay', 'Water Saturation',\n",
      "       'log_ID'],\n",
      "      dtype='object') \n",
      "\n",
      "seismic_df:  Index(['Time', 'Seismic', 'log_ID', 'QuadTrace', 'SecDerInstAmpl',\n",
      "       'Intergated', 'AWCP', 'Der', 'AWF', 'DomF', 'InstF', 'SecDer', 'AmpEn',\n",
      "       'AppPolr'],\n",
      "      dtype='object') \n",
      "\n",
      "section_stack:  Index(['Time', 'DomF', 'Trace', 'AppPolr', 'Seismic', 'Der', 'QuadrTrace',\n",
      "       'SecDerInstAmpl', 'Integrated', 'AmpEnv', 'Velocity', 'Density', 'AWF',\n",
      "       'SecDer', 'AWCP', 'InstF'],\n",
      "      dtype='object') \n",
      "\n",
      "section_stack2:  Index(['Time', 'P-imp', 'Trace', 'Porosity', 'Dn', 'Vcl', 'P-wave', 'Seismic'], dtype='object') \n",
      "\n",
      "log and section_stack:  Index(['P_wave', 'Porosity', 'V_clay', 'Water Saturation', 'log_ID'], dtype='object') \n",
      "\n",
      "seismic_df and section_stack:  Index(['AmpEn', 'Intergated', 'QuadTrace', 'log_ID'], dtype='object') \n",
      "\n",
      "log and section_stack2:  Index(['Density', 'P_wave', 'V_clay', 'Water Saturation', 'log_ID'], dtype='object') \n",
      "\n",
      "section_stack and section_stack2:  Index(['AWCP', 'AWF', 'AmpEnv', 'AppPolr', 'Density', 'Der', 'DomF', 'InstF',\n",
      "       'Integrated', 'QuadrTrace', 'SecDer', 'SecDerInstAmpl', 'Velocity'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if you need to rename some columns\n",
    "print('logs: ', logs.columns, '\\n')\n",
    "print ('seismic_df: ', seismic_df.columns, '\\n')\n",
    "print ('section_stack: ', section_stack.columns, '\\n')\n",
    "print ('section_stack2: ', section_stack2.columns, '\\n')\n",
    "\n",
    "# find deffierence in column names\n",
    "print ('log and section_stack: ', logs.columns.difference(section_stack.columns), '\\n')\n",
    "print('seismic_df and section_stack: ', (seismic_df.columns).difference(section_stack.columns), '\\n')\n",
    "print ('log and section_stack2: ', logs.columns.difference(section_stack2.columns), '\\n')\n",
    "print('section_stack and section_stack2: ', (section_stack.columns).difference(section_stack2.columns), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "120d461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "section_stack.rename(columns={'Velocity':'P_wave'}, inplace=True)\n",
    "seismic_df.rename(columns={'Intergated':'Integrated', \n",
    "                           'AmpEn':'AmpEnv', \n",
    "                           'QuadTrace':'QuadrTrace'}, inplace=True)\n",
    "\n",
    "section_stack.rename(columns={'Dn':'Density', \n",
    "                              'P-wave':'P_wave', \n",
    "                              'Vcl':'V_clay'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f5212",
   "metadata": {},
   "source": [
    "## Add horizons\n",
    "Horizon| 6507/3-9s | 6507/2-4 | 6507/2-2 | 6507/2-1\n",
    "---|---|---|---|---\n",
    "2D-wb| 488 |492 |516 | 512\n",
    "2D-mid | 1835 |1827 |1831| 1831\n",
    "2D-mid2 | 2714 |2726 |2694 |2830\n",
    "2D-K65 | 3022 |3082 |3050 |3169\n",
    "2D-BCU |3241 |3233 |3110 |3257\n",
    "2D-bottom | Time_max | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b9f291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom=max(logs['Time'].max(), seismic_df['Time'].max())\n",
    "horison_logs=pd.DataFrame(np.array([['2D-wd', 488, 492, 516, 512], ['2D-mid', 1835, 1827, 1831, 1831], \n",
    "                      ['2D-mid2', 2714, 2726, 2694, 2830], ['2D-K65', 3022, 3082, 3050, 3169], \n",
    "                      ['2D-BCU', 3241, 3233, 3110, 3257], ['2D-bottom', bottom, bottom, bottom, bottom]]),\n",
    "             columns=['Horison', '6507_3-9S', '6507_2-4', '6507_2-2', '6507_2-1'])\n",
    "\n",
    "# reshape df (unstack)\n",
    "horison_logs=horison_logs.melt(id_vars='Horison', var_name='log_ID', value_name='Time')\n",
    "horison_logs['Time']=horison_logs['Time'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "391afe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine logs + horisons\n",
    "\n",
    "# add horisons \n",
    "logs=pd.concat([logs, horison_logs], join='outer').sort_values(['log_ID', 'Time']).reset_index(drop=True)\n",
    "\n",
    "# backward fill horisons missing values\n",
    "logs['Horison']=logs['Horison'].fillna(method='bfill')\n",
    "\n",
    "logs=logs[~logs['P_wave'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84d99c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons=pd.read_csv('Data/2D_horizons.csv', skiprows=10)\n",
    "\n",
    "horizons=horizons.rename(columns={'<CDP>': 'CDP',\n",
    "                         '<Domain: 2D-': '2D-BCU',\n",
    "                          'BCU> <Domain:': '2D-bottom',\n",
    "                          '2D-bottom> <Domain': '2D-K65',\n",
    "                          ': 2D-K65> <Dom':'2D-mid', \n",
    "                          'D-mid> <Doma':'2D-mid2',\n",
    "                          'in: 2D-mid2> <':'2D-wb'})\n",
    "\n",
    "horizons=horizons.drop(['ain: 2','Domain: 2D-wb>' ], axis=1)\n",
    "# add bottom value \n",
    "horizons['bottom']=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b377cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDP</th>\n",
       "      <th>2D-BCU</th>\n",
       "      <th>2D-bottom</th>\n",
       "      <th>2D-K65</th>\n",
       "      <th>2D-mid</th>\n",
       "      <th>2D-mid2</th>\n",
       "      <th>2D-wb</th>\n",
       "      <th>bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2466.5352</td>\n",
       "      <td>3078.6089</td>\n",
       "      <td>2460.0000</td>\n",
       "      <td>1724.6871</td>\n",
       "      <td>2411.2976</td>\n",
       "      <td>509.44284</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2466.5352</td>\n",
       "      <td>3079.8782</td>\n",
       "      <td>2460.0000</td>\n",
       "      <td>1724.2711</td>\n",
       "      <td>2410.4529</td>\n",
       "      <td>509.44284</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2466.5352</td>\n",
       "      <td>3081.0125</td>\n",
       "      <td>2460.0000</td>\n",
       "      <td>1725.1711</td>\n",
       "      <td>2410.4529</td>\n",
       "      <td>509.44284</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2485.7712</td>\n",
       "      <td>3083.6541</td>\n",
       "      <td>2465.4553</td>\n",
       "      <td>1725.8091</td>\n",
       "      <td>2415.5444</td>\n",
       "      <td>509.08835</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2505.0073</td>\n",
       "      <td>3085.8909</td>\n",
       "      <td>2471.8271</td>\n",
       "      <td>1727.4093</td>\n",
       "      <td>2420.6357</td>\n",
       "      <td>508.96198</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>790</td>\n",
       "      <td>3577.1155</td>\n",
       "      <td>4618.8940</td>\n",
       "      <td>3257.0779</td>\n",
       "      <td>1808.4211</td>\n",
       "      <td>2861.4380</td>\n",
       "      <td>433.26376</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>791</td>\n",
       "      <td>3579.8704</td>\n",
       "      <td>4623.3291</td>\n",
       "      <td>3259.6245</td>\n",
       "      <td>1809.7360</td>\n",
       "      <td>2862.6533</td>\n",
       "      <td>437.00485</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>792</td>\n",
       "      <td>3582.6707</td>\n",
       "      <td>4627.3184</td>\n",
       "      <td>3260.4734</td>\n",
       "      <td>1805.0125</td>\n",
       "      <td>2864.1213</td>\n",
       "      <td>439.36432</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>793</td>\n",
       "      <td>3584.2341</td>\n",
       "      <td>4629.3965</td>\n",
       "      <td>3262.8542</td>\n",
       "      <td>1804.6062</td>\n",
       "      <td>2864.9619</td>\n",
       "      <td>440.02606</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>794</td>\n",
       "      <td>3585.6912</td>\n",
       "      <td>4631.2407</td>\n",
       "      <td>3265.7297</td>\n",
       "      <td>1804.4202</td>\n",
       "      <td>2865.8364</td>\n",
       "      <td>439.46964</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CDP     2D-BCU  2D-bottom     2D-K65     2D-mid    2D-mid2      2D-wb  \\\n",
       "0      1  2466.5352  3078.6089  2460.0000  1724.6871  2411.2976  509.44284   \n",
       "1      2  2466.5352  3079.8782  2460.0000  1724.2711  2410.4529  509.44284   \n",
       "2      3  2466.5352  3081.0125  2460.0000  1725.1711  2410.4529  509.44284   \n",
       "3      4  2485.7712  3083.6541  2465.4553  1725.8091  2415.5444  509.08835   \n",
       "4      5  2505.0073  3085.8909  2471.8271  1727.4093  2420.6357  508.96198   \n",
       "..   ...        ...        ...        ...        ...        ...        ...   \n",
       "789  790  3577.1155  4618.8940  3257.0779  1808.4211  2861.4380  433.26376   \n",
       "790  791  3579.8704  4623.3291  3259.6245  1809.7360  2862.6533  437.00485   \n",
       "791  792  3582.6707  4627.3184  3260.4734  1805.0125  2864.1213  439.36432   \n",
       "792  793  3584.2341  4629.3965  3262.8542  1804.6062  2864.9619  440.02606   \n",
       "793  794  3585.6912  4631.2407  3265.7297  1804.4202  2865.8364  439.46964   \n",
       "\n",
       "     bottom  \n",
       "0      5000  \n",
       "1      5000  \n",
       "2      5000  \n",
       "3      5000  \n",
       "4      5000  \n",
       "..      ...  \n",
       "789    5000  \n",
       "790    5000  \n",
       "791    5000  \n",
       "792    5000  \n",
       "793    5000  \n",
       "\n",
       "[794 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb9dd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange dataframe \n",
    "# Trace 1 - hor 1 - value\n",
    "# Trace 1 - hor 2 - value\n",
    "horison_unstacked=pd.DataFrame(horizons.set_index('CDP').stack()).reset_index()\n",
    "# rename columns\n",
    "horison_unstacked=horison_unstacked.rename(columns={'CDP':'Trace','level_1':'Horison', 0:'Time'})\n",
    "# sort by Trace name and Time \n",
    "horison_unstacked=horison_unstacked.sort_values(['Trace','Time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a98c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_stack['Time']=section_stack.Time.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b58dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add horisons \n",
    "section_stack=pd.merge(section_stack, horison_unstacked, how='outer', on=['Trace', 'Time']).sort_values(['Trace', 'Time'])\n",
    "\n",
    "# backward fill horisons missing values\n",
    "section_stack['Horison']=section_stack['Horison'].fillna(method='bfill')\n",
    "\n",
    "# drop all missing values\n",
    "section_stack=section_stack[~section_stack['Density'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f389c",
   "metadata": {},
   "source": [
    "## Save dataframes to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1300a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.to_csv('data/logs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc67e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_df.to_csv('data/seismic_logs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7082d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_stack.to_csv('data/section_2D_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38d0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_stack2.to_csv('data/section_2D_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f39ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
